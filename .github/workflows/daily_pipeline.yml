name: daily_pipeline

on:
  workflow_dispatch:
  schedule:
    - cron:  "0 */4 * * *"

jobs:
  daily_pipeline:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        sudo apt update
        sudo apt install ghostscript
        python -m pip install --upgrade pip
        python -m pip install flake8 pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        pip install build

    - name: 1) Run workflows/download_from_meteo.py
      run: |
        export PYTHONPATH="$PYTHONPATH:./src"
        python workflows/download_from_meteo.py 

    - name: 2) Run workflows/parse_all.py
      run: |
        export PYTHONPATH="$PYTHONPATH:./src"
        python workflows/parse_all.py 

    - name: 3) Run workflows/build_summaries.py
      run: |
        export PYTHONPATH="$PYTHONPATH:./src"
        python workflows/build_summaries.py 

    - name: Checkout repo branch data
      uses: actions/checkout@v2
      with:
        ref: 'data'
        token: "${{ secrets.REPO_DATA_TOKEN }}"

    - name: Copy data, and push to repo branch data
      run: |
        git config --global user.email "${{ secrets.GIT_USER_EMAIL }}"
        git config --global user.name "${{ secrets.GIT_USER_NAME }}"
        git pull origin data
        cp -r /tmp/weather_lk/* .
        echo "* $(date) daily_pipeline" >> update.log
        git add .
        git commit -m "ğŸ¤– $(date) - daily_pipeline.yml"
        git push origin data
